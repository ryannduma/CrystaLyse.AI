"""
Crystal structure storage and file management system.

This module handles the organisation, storage, and retrieval of crystal structure
files generated by Chemeleon CSP tools. It provides a structured approach to
managing CIF files, metadata, and analysis results for materials discovery workflows.
"""

import json
import hashlib
from datetime import datetime
from pathlib import Path
from typing import Dict, List, Optional, Any, Union
import shutil


class StructureStorage:
    """Manage crystal structure files and metadata."""
    
    def __init__(self, base_dir: Union[str, Path] = None):
        """Initialise storage system.
        
        Args:
            base_dir: Base directory for structure storage. Defaults to 'crystal_structures'
        """
        if base_dir is None:
            base_dir = Path.cwd() / "crystal_structures"
        
        self.base_dir = Path(base_dir)
        self.base_dir.mkdir(exist_ok=True)
        
        # Create subdirectories
        self.cif_dir = self.base_dir / "cif_files"
        self.json_dir = self.base_dir / "json_data"
        self.reports_dir = self.base_dir / "html_reports"
        self.mace_dir = self.base_dir / "mace_inputs"
        
        for directory in [self.cif_dir, self.json_dir, self.reports_dir, self.mace_dir]:
            directory.mkdir(exist_ok=True)
        
        self.metadata_file = self.base_dir / "metadata.json"
        self.metadata = self._load_metadata()
    
    def _load_metadata(self) -> Dict:
        """Load metadata from file."""
        if self.metadata_file.exists():
            try:
                return json.loads(self.metadata_file.read_text())
            except json.JSONDecodeError:
                return {}
        return {}
    
    def _save_metadata(self):
        """Save metadata to file."""
        self.metadata_file.write_text(json.dumps(self.metadata, indent=2))
    
    def store_structures(self, composition: str, structures: List[Dict], 
                        analysis_params: Dict, session_id: str = None) -> Dict:
        """Store crystal structures with comprehensive metadata.
        
        Args:
            composition: Chemical composition (e.g., "CaTiO3")
            structures: List of structure dictionaries from Chemeleon
            analysis_params: Parameters used for structure generation
            session_id: Optional session identifier
        
        Returns:
            Dictionary with storage information and file paths
        """
        # Generate unique identifiers
        timestamp = datetime.now().isoformat()
        run_id = hashlib.md5(f"{composition}_{timestamp}".encode()).hexdigest()[:8]
        
        if session_id is None:
            session_id = f"session_{datetime.now().strftime('%Y%m%d_%H%M%S')}"
        
        # Create composition directory
        comp_dir = self.cif_dir / self._sanitize_filename(composition)
        comp_dir.mkdir(exist_ok=True)
        
        stored_files = {
            'cif_paths': [],
            'json_paths': [],
            'composition': composition,
            'run_id': run_id,
            'session_id': session_id,
            'timestamp': timestamp,
            'num_structures': len(structures)
        }
        
        # Store each structure
        for i, struct in enumerate(structures):
            base_filename = f"{composition}_{run_id}_{i:03d}"
            
            # Save CIF file
            if 'cif' in struct:
                cif_path = comp_dir / f"{base_filename}.cif"
                cif_path.write_text(struct['cif'])
                stored_files['cif_paths'].append(str(cif_path))
            
            # Save structure data as JSON
            json_data = {
                'structure': struct.get('structure', {}),
                'analysis': struct.get('analysis', {}),
                'cif': struct.get('cif', ''),
                'generation_params': analysis_params,
                'metadata': {
                    'composition': composition,
                    'structure_index': i,
                    'run_id': run_id,
                    'session_id': session_id,
                    'timestamp': timestamp,
                    'formula': struct.get('formula', composition)
                }
            }
            
            json_path = self.json_dir / f"{base_filename}.json"
            json_path.write_text(json.dumps(json_data, indent=2))
            stored_files['json_paths'].append(str(json_path))
        
        # Update global metadata
        if composition not in self.metadata:
            self.metadata[composition] = []
        
        self.metadata[composition].append({
            'run_id': run_id,
            'session_id': session_id,
            'timestamp': timestamp,
            'num_structures': len(structures),
            'cif_paths': stored_files['cif_paths'],
            'json_paths': stored_files['json_paths'],
            'analysis_params': analysis_params
        })
        
        self._save_metadata()
        return stored_files
    
    def store_visualisation_report(self, composition: str, html_content: str, 
                                 run_id: str = None) -> Path:
        """Store HTML visualisation report.
        
        Args:
            composition: Chemical composition
            html_content: HTML report content
            run_id: Run identifier (if None, uses latest for composition)
        
        Returns:
            Path to saved report file
        """
        if run_id is None:
            # Use latest run for this composition
            if composition in self.metadata and self.metadata[composition]:
                run_id = self.metadata[composition][-1]['run_id']
            else:
                run_id = "unknown"
        
        report_filename = f"{self._sanitize_filename(composition)}_{run_id}_report.html"
        report_path = self.reports_dir / report_filename
        report_path.write_text(html_content)
        
        return report_path
    
    def get_structures_for_composition(self, composition: str, 
                                     run_id: str = None) -> List[Dict]:
        """Retrieve structures for a given composition.
        
        Args:
            composition: Chemical composition to search for
            run_id: Specific run ID (if None, returns all runs)
        
        Returns:
            List of structure dictionaries
        """
        if composition not in self.metadata:
            return []
        
        structures = []
        runs = self.metadata[composition]
        
        if run_id:
            runs = [run for run in runs if run['run_id'] == run_id]
        
        for run in runs:
            for json_path in run['json_paths']:
                if Path(json_path).exists():
                    try:
                        struct_data = json.loads(Path(json_path).read_text())
                        structures.append(struct_data)
                    except (json.JSONDecodeError, FileNotFoundError):
                        continue
        
        return structures
    
    def list_compositions(self) -> List[str]:
        """Get list of all stored compositions."""
        return list(self.metadata.keys())
    
    def get_composition_info(self, composition: str) -> Dict:
        """Get detailed information about a composition.
        
        Args:
            composition: Chemical composition
        
        Returns:
            Dictionary with composition metadata
        """
        if composition not in self.metadata:
            return {}
        
        runs = self.metadata[composition]
        total_structures = sum(run['num_structures'] for run in runs)
        
        return {
            'composition': composition,
            'num_runs': len(runs),
            'total_structures': total_structures,
            'runs': runs,
            'latest_run': runs[-1] if runs else None
        }
    
    def prepare_mace_input(self, composition: str = None, 
                          max_structures: int = None) -> Path:
        """Prepare structures for MACE forcefield calculations.
        
        Args:
            composition: Specific composition (if None, includes all)
            max_structures: Maximum structures to include
        
        Returns:
            Path to MACE input file
        """
        structures_data = []
        
        if composition:
            compositions = [composition]
        else:
            compositions = self.list_compositions()
        
        structure_count = 0
        for comp in compositions:
            structures = self.get_structures_for_composition(comp)
            
            for struct_data in structures:
                if max_structures and structure_count >= max_structures:
                    break
                
                # Convert to MACE format
                mace_entry = {
                    'composition': comp,
                    'structure': struct_data.get('structure', {}),
                    'energy': None,  # To be calculated by MACE
                    'forces': None,  # To be calculated by MACE
                    'stress': None,  # To be calculated by MACE
                    'metadata': struct_data.get('metadata', {})
                }
                
                structures_data.append(mace_entry)
                structure_count += 1
            
            if max_structures and structure_count >= max_structures:
                break
        
        # Save MACE input file
        timestamp = datetime.now().strftime('%Y%m%d_%H%M%S')
        filename = f"mace_input_{timestamp}.json"
        if composition:
            filename = f"mace_input_{self._sanitize_filename(composition)}_{timestamp}.json"
        
        mace_path = self.mace_dir / filename
        mace_path.write_text(json.dumps(structures_data, indent=2))
        
        return mace_path
    
    def export_structures(self, composition: str, export_format: str = "cif", 
                         output_dir: Path = None) -> List[Path]:
        """Export structures in specified format.
        
        Args:
            composition: Chemical composition to export
            export_format: Export format ('cif', 'json', 'both')
            output_dir: Output directory (if None, creates export subdirectory)
        
        Returns:
            List of exported file paths
        """
        if output_dir is None:
            output_dir = self.base_dir / "exports" / self._sanitize_filename(composition)
        
        output_dir = Path(output_dir)
        output_dir.mkdir(parents=True, exist_ok=True)
        
        exported_files = []
        structures = self.get_structures_for_composition(composition)
        
        for i, struct_data in enumerate(structures):
            base_name = f"{composition}_structure_{i:03d}"
            
            if export_format in ['cif', 'both'] and 'cif' in struct_data:
                cif_path = output_dir / f"{base_name}.cif"
                cif_path.write_text(struct_data['cif'])
                exported_files.append(cif_path)
            
            if export_format in ['json', 'both']:
                json_path = output_dir / f"{base_name}.json"
                json_path.write_text(json.dumps(struct_data, indent=2))
                exported_files.append(json_path)
        
        return exported_files
    
    def cleanup_old_runs(self, days_old: int = 30):
        """Clean up old structure files and metadata.
        
        Args:
            days_old: Remove runs older than this many days
        """
        cutoff_date = datetime.now().timestamp() - (days_old * 24 * 3600)
        
        for composition in list(self.metadata.keys()):
            runs = self.metadata[composition]
            updated_runs = []
            
            for run in runs:
                try:
                    run_date = datetime.fromisoformat(run['timestamp']).timestamp()
                    if run_date >= cutoff_date:
                        updated_runs.append(run)
                    else:
                        # Remove associated files
                        for file_path in run.get('cif_paths', []) + run.get('json_paths', []):
                            try:
                                Path(file_path).unlink(missing_ok=True)
                            except OSError:
                                pass
                except (ValueError, KeyError):
                    # Keep runs with invalid timestamps
                    updated_runs.append(run)
            
            if updated_runs:
                self.metadata[composition] = updated_runs
            else:
                del self.metadata[composition]
        
        self._save_metadata()
    
    def get_storage_stats(self) -> Dict:
        """Get storage system statistics."""
        stats = {
            'total_compositions': len(self.metadata),
            'total_runs': sum(len(runs) for runs in self.metadata.values()),
            'total_structures': sum(
                sum(run['num_structures'] for run in runs)
                for runs in self.metadata.values()
            ),
            'total_cif_files': len(list(self.cif_dir.rglob("*.cif"))),
            'total_json_files': len(list(self.json_dir.rglob("*.json"))),
            'total_reports': len(list(self.reports_dir.rglob("*.html"))),
            'storage_size_mb': self._get_directory_size(self.base_dir) / (1024 * 1024),
            'compositions': list(self.metadata.keys())
        }
        
        return stats
    
    def _sanitize_filename(self, filename: str) -> str:
        """Sanitize filename for filesystem compatibility."""
        # Replace problematic characters
        sanitized = "".join(c for c in filename if c.isalnum() or c in "._-")
        return sanitized[:100]  # Limit length
    
    def _get_directory_size(self, directory: Path) -> int:
        """Calculate total size of directory in bytes."""
        total_size = 0
        for path in directory.rglob("*"):
            if path.is_file():
                try:
                    total_size += path.stat().st_size
                except OSError:
                    pass
        return total_size